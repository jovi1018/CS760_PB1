{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import io\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:48:13.264390Z","iopub.execute_input":"2021-10-11T23:48:13.264596Z","iopub.status.idle":"2021-10-11T23:48:18.617699Z","shell.execute_reply.started":"2021-10-11T23:48:13.264573Z","shell.execute_reply":"2021-10-11T23:48:18.616956Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os  \nimport cv2\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\n\n# Loading np array from images\ndef make_dataset(labels, dir_path, IMG_SIZE = 150, size = 200):\n    # initial an empty list X to store image of np.array()\n    X = []\n\n    # initial an empty list Z to store labels/names of cat individauls\n    Z = []\n    \n    \n    for label in labels:\n        DIR = dir_path + label\n        #n = 0\n        for img in tqdm(os.listdir(DIR)):\n            path = os.path.join(DIR,img)\n            #while n < size:\n            # reading images\n            img = cv2.imread(path,cv2.IMREAD_COLOR)\n            # resizing images to (150, 150, 3), 3 is the number of channels - RGB\n            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n\n            X.append(np.array(img))\n            Z.append(str(label))\n                \n                #n += 1\n            \n    ## Transform labels in Z to Y from class number\n    le=LabelEncoder()\n    Y=le.fit_transform(Z)\n\n    ## Transform and normalize X in the range of [0, 1]\n    X=np.array(X)\n    X=X/255.\n    return X, Y","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:48:18.619639Z","iopub.execute_input":"2021-10-11T23:48:18.619890Z","iopub.status.idle":"2021-10-11T23:48:19.412533Z","shell.execute_reply.started":"2021-10-11T23:48:18.619858Z","shell.execute_reply":"2021-10-11T23:48:19.411774Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"dir_path = '/kaggle/input/auckland-zoom-monkeys/Auckland_Zoo_Monkeys/'\n\nlabels = ['Arani', 'Inti', 'Ocuri', 'Poco', 'Rattaplan', 'Romy']\n\n# randomly select seen datset and unseen dataset\n# make open set and unseen set \ndef make_seen_unseen(labels, num_seen):\n    arr = np.arange(len(labels))\n    np.random.shuffle(arr)\n    \n    labels_seen = [labels[i] for i in arr[:num_seen]]\n    labels_unseen = [labels[i] for i in arr[num_seen:]]\n    \n    X_seen, Y_seen = make_dataset(labels_seen, dir_path)\n    X_unseen, Y_unseen = make_dataset(labels_unseen, dir_path)\n    Y_unseen = ['unseen'] * len(Y_unseen)\n    Y_unseen = np.array(Y_unseen)\n    return X_seen, Y_seen, X_unseen, Y_unseen","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:48:19.415725Z","iopub.execute_input":"2021-10-11T23:48:19.415965Z","iopub.status.idle":"2021-10-11T23:48:19.423747Z","shell.execute_reply.started":"2021-10-11T23:48:19.415941Z","shell.execute_reply":"2021-10-11T23:48:19.422831Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Configuration settings","metadata":{}},{"cell_type":"code","source":"imsize = 150\nEPOCHS = 5\nbatch_size = 16\nembeddingDim = 128\nnum_individuals = len(labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:48:19.426107Z","iopub.execute_input":"2021-10-11T23:48:19.426588Z","iopub.status.idle":"2021-10-11T23:48:19.432937Z","shell.execute_reply.started":"2021-10-11T23:48:19.426554Z","shell.execute_reply":"2021-10-11T23:48:19.432188Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_seen, Y_seen, X_unseen, Y_unseen = make_seen_unseen(labels, num_individuals - 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:48:19.435287Z","iopub.execute_input":"2021-10-11T23:48:19.435536Z","iopub.status.idle":"2021-10-11T23:48:54.043552Z","shell.execute_reply.started":"2021-10-11T23:48:19.435501Z","shell.execute_reply":"2021-10-11T23:48:54.042753Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Train/test set split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X_seen, Y_seen, test_size = 0.2, stratify = Y_seen, random_state=2021)\n\nX_val_unseen, X_test_unseen, Y_val_unseen, Y_test_unseen = train_test_split(X_unseen, Y_unseen, test_size = 0.5, random_state=2021)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:48:54.044939Z","iopub.execute_input":"2021-10-11T23:48:54.045376Z","iopub.status.idle":"2021-10-11T23:48:54.388387Z","shell.execute_reply.started":"2021-10-11T23:48:54.045338Z","shell.execute_reply":"2021-10-11T23:48:54.387595Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Stratified 3 fold Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=3, random_state=2021, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:48:54.389608Z","iopub.execute_input":"2021-10-11T23:48:54.389870Z","iopub.status.idle":"2021-10-11T23:48:54.395521Z","shell.execute_reply.started":"2021-10-11T23:48:54.389838Z","shell.execute_reply":"2021-10-11T23:48:54.393858Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# VGG16 Classification Model","metadata":{}},{"cell_type":"code","source":"def evaluate_vgg16(lr):\n    base_model_16 = tf.keras.applications.vgg16.VGG16(include_top=False,\n                      input_shape = (imsize,imsize,3),\n                      weights = 'imagenet')\n\n    # freeze all the layers of VGG, so they won't be trained.\n    for layer in base_model_16.layers:\n        layer.trainable = False\n\n    model_vgg_16 = tf.keras.models.Sequential([\n        base_model_16,\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(units=1024, activation='relu'),\n        tf.keras.layers.Dense(units=num_individuals, activation='softmax')\n    ])\n\n    model_vgg_16.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='sparse_categorical_crossentropy', metrics=['acc']) \n\n    model_vgg_16.fit(x=x_train, y=y_train,\n                     epochs=EPOCHS,\n                     batch_size=batch_size,\n                     verbose=1)\n    \n    acc = model_vgg_16.evaluate(x_val, y_val)[1]\n    \n    return acc","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:48:54.396793Z","iopub.execute_input":"2021-10-11T23:48:54.397052Z","iopub.status.idle":"2021-10-11T23:48:54.406061Z","shell.execute_reply.started":"2021-10-11T23:48:54.397018Z","shell.execute_reply":"2021-10-11T23:48:54.405296Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"lr = [1e-5, 1e-4, 1e-3, 1e-2]\n\nterms = {}\nfor i in lr:\n    terms['{}'.format(i)] = []\n\nfor train_index, test_index in skf.split(X_train, Y_train):\n    x_train,x_val,y_train,y_val = X_train[train_index], X_train[test_index], Y_train[train_index], Y_train[test_index]\n    \n    for i in lr:\n        terms['{}'.format(i)].append(evaluate_vgg16(lr = i))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:48:54.408509Z","iopub.execute_input":"2021-10-11T23:48:54.408804Z","iopub.status.idle":"2021-10-11T23:50:30.993549Z","shell.execute_reply.started":"2021-10-11T23:48:54.408772Z","shell.execute_reply":"2021-10-11T23:50:30.992862Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nacc = pd.DataFrame(terms)\ntable_vgg16 = acc.agg(['mean', 'std']).T\ntable_vgg16","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:50:30.995024Z","iopub.execute_input":"2021-10-11T23:50:30.995383Z","iopub.status.idle":"2021-10-11T23:50:31.030203Z","shell.execute_reply.started":"2021-10-11T23:50:30.995348Z","shell.execute_reply":"2021-10-11T23:50:31.029522Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Retrain VGG16 model on training set + val set, test it on test set","metadata":{}},{"cell_type":"code","source":"# choose best lr\nlr = 0.001 \n\nbase_model_16 = tf.keras.applications.vgg16.VGG16(include_top=False,\n                      input_shape = (imsize,imsize,3),\n                      weights = 'imagenet')\n\n# freeze all the layers of VGG, so they won't be trained.\nfor layer in base_model_16.layers:\n    layer.trainable = False\n\nmodel_vgg_16 = tf.keras.models.Sequential([\n    base_model_16,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=1024, activation='relu'),\n    tf.keras.layers.Dense(units=num_individuals, activation='softmax')\n])\n\nmodel_vgg_16.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='sparse_categorical_crossentropy', metrics=['acc']) \n\nmodel_vgg_16.fit(x=X_train, y=Y_train,\n                 epochs=EPOCHS,\n                 batch_size=batch_size,\n                 verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:18:47.309709Z","iopub.execute_input":"2021-10-12T00:18:47.310018Z","iopub.status.idle":"2021-10-12T00:18:55.959698Z","shell.execute_reply.started":"2021-10-12T00:18:47.309983Z","shell.execute_reply":"2021-10-12T00:18:55.959050Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"acc_vgg16 = round(model_vgg_16.evaluate(X_test, Y_test)[1], 2)\n\nprint('Accuracy of VGG16 on the test set is {}'.format(acc_vgg16))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:18:55.960960Z","iopub.execute_input":"2021-10-12T00:18:55.961198Z","iopub.status.idle":"2021-10-12T00:18:56.554799Z","shell.execute_reply.started":"2021-10-12T00:18:55.961167Z","shell.execute_reply":"2021-10-12T00:18:56.553661Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Contrastive Loss","metadata":{}},{"cell_type":"code","source":"# Helper Function \n\n# Create positive pairs and negative pairs\nimport random\ndef create_pairs(images, labels):\n    # initialize two empty lists to hold the (image, image) pairs and\n    # labels to indicate if a pair is positive (0) or negative (1)\n    np.random.seed(2021)\n    pairImages = []\n    pairLabels = []\n    \n    # calculate the total number of classes present in the dataset\n    # and then build a list of indexes for each class label that\n    # provides the indexes for all examples with a given label\n    idx = [np.where(labels == i)[0] for i in range(num_individuals)]\n    \n    # loop voer all images\n    for idxA in range(len(images)):\n        # grab the current image and label belonging to the current iteration\n        currentImage = images[idxA]\n        label = labels[idxA]\n        \n        # randomly pick on an image that belongs to the *same* class label\n        posId = random.choice(idx[label])\n        posImage = images[posId]\n        \n        # prepare a positive pair and update the images and labels\n        pairImages.append([currentImage, posImage])\n        pairLabels.append([0])\n        \n        # grab the indices for each of the class labels *not* equal to\n        # the current label and randomly pick an image corresponding\n        # to a label *not* equal to the current label\n        negId = np.where(labels != label)[0]\n        negIdx = random.choice(negId)\n        negImage = images[negIdx]\n        \n        # prepare a negative pair of images and update out lists\n        pairImages.append([currentImage, negImage])\n        pairLabels.append([1])\n    \n    return (np.array(pairImages), np.array(pairLabels))\n\n\n\n# Function to calculate the distance between two images (Euclidean Distance used here)\nimport tensorflow.keras.backend as K\ndef euclidean_distance(vectors):\n    # unpack the vectors into separate lists\n    (featsA, featsB) = vectors\n    # compute the sum of squared distances between the vectors\n    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n                       keepdims=True)\n    # return the euclidean distance between the vectors\n    return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n\n\n# contrastive loss function\ndef contrastive_loss(y, preds, margin=1):\n    # explicitly cast the true class label data type to the predicted\n    # class label data type (otherwise we run the risk of having two\n    # separate data types, causing TensorFlow to error out)\n    y = tf.cast(y, preds.dtype)\n    # calculate the contrastive loss between the true labels and\n    # the predicted labels\n    squaredPreds = K.square(preds)\n    squaredMargin = K.square(K.maximum(margin - preds, 0))\n    loss = K.mean((1 - y) * squaredPreds + y * squaredMargin)\n    # return the computed contrastive loss to the calling function\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:50:42.047256Z","iopub.execute_input":"2021-10-11T23:50:42.047753Z","iopub.status.idle":"2021-10-11T23:50:42.060521Z","shell.execute_reply.started":"2021-10-11T23:50:42.047714Z","shell.execute_reply":"2021-10-11T23:50:42.059809Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Closed Set","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\ndef evaluate_cl_closed_set(lr, k):\n    base_model_16 = tf.keras.applications.vgg16.VGG16(include_top=False,\n                                                      input_shape = (imsize,imsize,3),\n                                                      weights = 'imagenet')\n    \n    # freeze all the layers of VGG, so they won't be trained.\n    for layer in base_model_16.layers:\n        layer.trainable = False\n\n    model_cl = tf.keras.models.Sequential([\n        base_model_16,\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(units=1024, activation='relu'),\n        tf.keras.layers.Dense(embeddingDim, activation=None), # No activation on final dense layer\n        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n    ])\n\n    \n    imgA = tf.keras.layers.Input(shape=((imsize, imsize, 3)))\n    imgB = tf.keras.layers.Input(shape=((imsize, imsize, 3)))\n    \n    featsA = model_cl(imgA)\n    featsB = model_cl(imgB)\n   \n    distance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])\n    model = tf.keras.Model(inputs=[imgA, imgB], outputs=distance)\n    model.compile(loss=contrastive_loss, optimizer=tf.keras.optimizers.Adam(lr))\n\n    model.fit([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n              batch_size = batch_size,\n              epochs=EPOCHS, \n              verbose=1)\n    \n    embedding_train_cl = []\n    for i in range(len(y_train)):\n        embedding_train_cl.append(model_cl.predict(x_train[i].reshape(1, imsize, imsize, 3))[0])\n    embedding_train_cl = np.array(embedding_train_cl, dtype=float) \n\n    knn_cl = KNeighborsClassifier(n_neighbors = k)\n    knn_cl.fit(embedding_train_cl, y_train)\n    \n    x_test_embedding = model_cl.predict(x_val)\n    acc = round(knn_cl.score(x_test_embedding, y_val), 2)\n    print('Accuracy on the val set with contrastive loss is {}'.format(acc))\n    \n    return acc","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:50:42.062106Z","iopub.execute_input":"2021-10-11T23:50:42.062423Z","iopub.status.idle":"2021-10-11T23:50:42.213683Z","shell.execute_reply.started":"2021-10-11T23:50:42.062388Z","shell.execute_reply":"2021-10-11T23:50:42.212973Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"lr = [1e-5, 1e-4, 1e-3, 1e-2]\nk = [1, 3, 5]\n\nterms = {}\nfor i in lr:\n    for j in k:\n        terms['{}_{}'.format(i, j)] = []\n\nfor train_index, test_index in skf.split(X_train, Y_train):\n    x_train,x_val,y_train,y_val = X_train[train_index], X_train[test_index], Y_train[train_index], Y_train[test_index]\n    \n    (pairTrain, labelTrain) = create_pairs(x_train, y_train)\n    \n    for i in lr:\n        for j in k:\n            terms['{}_{}'.format(i, j)].append(evaluate_cl_closed_set(lr = i, k = j))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:50:42.215006Z","iopub.execute_input":"2021-10-11T23:50:42.215263Z","iopub.status.idle":"2021-10-12T00:18:47.283601Z","shell.execute_reply.started":"2021-10-11T23:50:42.215231Z","shell.execute_reply":"2021-10-12T00:18:47.282777Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nacc = pd.DataFrame(terms)\ntable_cl_closed_set = acc.agg(['mean', 'std']).T\ntable_cl_closed_set","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:18:47.285895Z","iopub.execute_input":"2021-10-12T00:18:47.286331Z","iopub.status.idle":"2021-10-12T00:18:47.308343Z","shell.execute_reply.started":"2021-10-12T00:18:47.286294Z","shell.execute_reply":"2021-10-12T00:18:47.307607Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Retrain Contrastive Loss on trainset + val set, and test it on test set","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# choose best lr and k\nlr = 0.0001\nk = 1\n\nbase_model_16 = tf.keras.applications.vgg16.VGG16(include_top=False,\n                                                  input_shape = (imsize,imsize,3),\n                                                  weights = 'imagenet')\n    \n# freeze all the layers of VGG, so they won't be trained.\nfor layer in base_model_16.layers:\n    layer.trainable = False\n\nmodel_cl = tf.keras.models.Sequential([\n    base_model_16,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=1024, activation='relu'),\n    tf.keras.layers.Dense(embeddingDim, activation=None), # No activation on final dense layer\n    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n])\n\n    \nimgA = tf.keras.layers.Input(shape=((imsize, imsize, 3)))\nimgB = tf.keras.layers.Input(shape=((imsize, imsize, 3)))\n    \nfeatsA = model_cl(imgA)\nfeatsB = model_cl(imgB)\n   \ndistance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])\nmodel = tf.keras.Model(inputs=[imgA, imgB], outputs=distance)\nmodel.compile(loss=contrastive_loss, optimizer=tf.keras.optimizers.Adam(lr))\n\n(pairTrain, labelTrain) = create_pairs(X_train, Y_train)\n\nmodel.fit([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n          batch_size = batch_size,\n          epochs=EPOCHS, \n          verbose=1)\n    \nembedding_train_cl = []\nfor i in range(len(Y_train)):\n        embedding_train_cl.append(model_cl.predict(X_train[i].reshape(1, imsize, imsize, 3))[0])\nembedding_train_cl = np.array(embedding_train_cl, dtype=float) \n\nknn_cl = KNeighborsClassifier(n_neighbors = k)\nknn_cl.fit(embedding_train_cl, Y_train)\n    \nx_test_embedding = model_cl.predict(X_test)\nacc_cl_closed_set = round(knn_cl.score(x_test_embedding, Y_test), 2)\n\nprint('Accuracy of Constractive Loss on test set is {}'.format(round(acc_cl_closed_set, 2)))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:20:10.444303Z","iopub.execute_input":"2021-10-12T00:20:10.445044Z","iopub.status.idle":"2021-10-12T00:21:21.311864Z","shell.execute_reply.started":"2021-10-12T00:20:10.445007Z","shell.execute_reply":"2021-10-12T00:21:21.311137Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Open Set","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\ndef evaluate_cl_open_set(lr=0.0001, k = 1, d_t = 0.5):\n    base_model_16 = tf.keras.applications.vgg16.VGG16(include_top=False,\n                                                      input_shape = (imsize,imsize,3),\n                                                      weights = 'imagenet')\n    \n    # freeze all the layers of VGG, so they won't be trained.\n    for layer in base_model_16.layers:\n        layer.trainable = False\n\n    model_cl = tf.keras.models.Sequential([\n        base_model_16,\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(units=1024, activation='relu'),\n        tf.keras.layers.Dense(embeddingDim, activation=None), # No activation on final dense layer\n        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n    ])\n\n    \n    imgA = tf.keras.layers.Input(shape=((imsize, imsize, 3)))\n    imgB = tf.keras.layers.Input(shape=((imsize, imsize, 3)))\n    \n    featsA = model_cl(imgA)\n    featsB = model_cl(imgB)\n   \n    distance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])\n    model = tf.keras.Model(inputs=[imgA, imgB], outputs=distance)\n    model.compile(loss=contrastive_loss, optimizer=tf.keras.optimizers.Adam(lr))\n\n    model.fit([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n              batch_size = batch_size,\n              epochs=EPOCHS, \n              verbose=1)\n    \n    embedding_train_cl = []\n    for i in range(len(y_train)):\n        embedding_train_cl.append(model_cl.predict(x_train[i].reshape(1, imsize, imsize, 3))[0])\n    embedding_train_cl = np.array(embedding_train_cl, dtype=float) \n\n    knn_cl = KNeighborsClassifier(n_neighbors = k)\n    knn_cl.fit(embedding_train_cl, y_train)\n    \n    #find the center point for each class in training set\n    support_cl = []\n    for i in np.unique(y_train):\n        support_cl.append(np.mean(embedding_train_cl[y_train==i], axis=0))\n        \n    support_cl = np.array(support_cl, dtype=float)\n    \n    pred = []\n    temp_x = np.append(x_val, X_val_unseen, axis=0)\n    temp_y = np.append(y_val, Y_val_unseen, axis=0)\n    \n    arr = np.arange(temp_y.shape[0])\n    np.random.shuffle(arr)\n    \n    temp_x = temp_x[arr]\n    temp_y = temp_y[arr]\n    \n    for i in range(len(temp_y)):\n        dists = []\n        for j in range(len(np.unique(y_train))):\n            embedding_test = model_cl.predict(temp_x[i].reshape(1, 150, 150, 3))\n            embedding_anchor = support_cl[j]\n            dist = np.sum((embedding_test - embedding_anchor) ** 2) ** (1/2)\n            dists.append(dist)\n        if min(dists) >= d_t:\n            pred.append('unseen')\n        else:\n            pred.append(knn_cl.predict(embedding_test)[0])\n\n    pred = np.array(pred)\n    \n    acc_open = round(np.mean(pred == temp_y), 2)\n    print('The accuracy on the val set with Contrastive Loss is {}'.format(acc_open))\n    \n    return acc_open","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:21:28.514507Z","iopub.execute_input":"2021-10-12T00:21:28.514804Z","iopub.status.idle":"2021-10-12T00:21:28.549283Z","shell.execute_reply.started":"2021-10-12T00:21:28.514774Z","shell.execute_reply":"2021-10-12T00:21:28.548517Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"d_t = [0.4, 0.5, 0.6]\n\nterms = {}\nfor i in d_t:\n    terms['{}'.format(i)] = []\n\nfor train_index, test_index in skf.split(X_train, Y_train):\n    x_train,x_val,y_train,y_val = X_train[train_index], X_train[test_index], Y_train[train_index], Y_train[test_index]\n    \n    (pairTrain, labelTrain) = create_pairs(x_train, y_train)\n    \n    for i in d_t:\n        terms['{}'.format(i)].append(evaluate_cl_open_set(d_t = i))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:21:32.291923Z","iopub.execute_input":"2021-10-12T00:21:32.292469Z","iopub.status.idle":"2021-10-12T00:43:26.079402Z","shell.execute_reply.started":"2021-10-12T00:21:32.292431Z","shell.execute_reply":"2021-10-12T00:43:26.078656Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nacc = pd.DataFrame(terms)\ntable_cl_open_set = acc.agg(['mean', 'std']).T\ntable_cl_open_set","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:43:26.081197Z","iopub.execute_input":"2021-10-12T00:43:26.081477Z","iopub.status.idle":"2021-10-12T00:43:26.098034Z","shell.execute_reply.started":"2021-10-12T00:43:26.081443Z","shell.execute_reply":"2021-10-12T00:43:26.096878Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Retrain Contrastive Loss on trainset + val set, and test it on test set","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# choose the best value of d_t\nlr = 0.0001\nk = 1\nd_t = 0.4\n\nbase_model_16 = tf.keras.applications.vgg16.VGG16(include_top=False,\n                                                  input_shape = (imsize,imsize,3),\n                                                  weights = 'imagenet')\n    \n# freeze all the layers of VGG, so they won't be trained.\nfor layer in base_model_16.layers:\n    layer.trainable = False\n\nmodel_cl = tf.keras.models.Sequential([\n    base_model_16,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=1024, activation='relu'),\n    tf.keras.layers.Dense(embeddingDim, activation=None), # No activation on final dense layer\n    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n])\n\nimgA = tf.keras.layers.Input(shape=((imsize, imsize, 3)))\nimgB = tf.keras.layers.Input(shape=((imsize, imsize, 3)))\n\nfeatsA = model_cl(imgA)\nfeatsB = model_cl(imgB)\n\ndistance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])\n\nmodel = tf.keras.Model(inputs=[imgA, imgB], outputs=distance)\n\nmodel.compile(loss=contrastive_loss, optimizer=tf.keras.optimizers.Adam(lr))\n\n(pairTrain, labelTrain) = create_pairs(X_train, Y_train)\n\nmodel.fit([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n        batch_size = batch_size,\n        epochs=EPOCHS, \n        verbose=1)\n\nembedding_train_cl = []\nfor i in range(len(Y_train)):\n    embedding_train_cl.append(model_cl.predict(X_train[i].reshape(1, imsize, imsize, 3))[0])\n\nembedding_train_cl = np.array(embedding_train_cl, dtype=float) \n\nknn_cl = KNeighborsClassifier(n_neighbors = k)\nknn_cl.fit(embedding_train_cl, Y_train)\n    \n#find the center point for each class in training set\nsupport_cl = []\nfor i in np.unique(Y_train):\n    support_cl.append(np.mean(embedding_train_cl[Y_train==i], axis=0))\n        \nsupport_cl = np.array(support_cl, dtype=float)\n    \npred = []\ntemp_x = np.append(X_test, X_val_unseen, axis=0)\ntemp_y = np.append(Y_test, Y_val_unseen, axis=0)\n    \narr = np.arange(temp_y.shape[0])\nnp.random.shuffle(arr)\n    \ntemp_x = temp_x[arr]\ntemp_y = temp_y[arr]\n    \nfor i in range(len(temp_y)):\n    dists = []\n    for j in range(len(np.unique(Y_train))):\n        embedding_test = model_cl.predict(temp_x[i].reshape(1, 150, 150, 3))\n        embedding_anchor = support_cl[j]\n        dist = np.sum((embedding_test - embedding_anchor) ** 2) ** (1/2)\n        dists.append(dist)\n    if min(dists) >= d_t:\n            pred.append('unseen')\n    else:\n        pred.append(knn_cl.predict(embedding_test)[0])\n\npred = np.array(pred)\n    \nacc_cl_open_set = round(np.mean(pred == temp_y), 2)\nprint('The accuracy on the test set with Open Dataset of Contrastive Loss is {}'.format(acc_cl_open_set))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:49:12.884453Z","iopub.execute_input":"2021-10-12T00:49:12.884737Z","iopub.status.idle":"2021-10-12T00:51:46.752931Z","shell.execute_reply.started":"2021-10-12T00:49:12.884709Z","shell.execute_reply":"2021-10-12T00:51:46.752173Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Triplet Loss","metadata":{}},{"cell_type":"markdown","source":"## Closed Set","metadata":{}},{"cell_type":"code","source":"def evaluate_tl_closed_set(lr, k):\n    base_model_16 = tf.keras.applications.vgg16.VGG16(include_top=False,\n                                                      input_shape = (imsize, imsize, 3),\n                                                      weights = 'imagenet')\n\n    # freeze all the layers of VGG, so they won't be trained.\n    for layer in base_model_16.layers:\n        layer.trainable = False\n\n    model_tl = tf.keras.models.Sequential([\n        base_model_16,\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(units=1024, activation='relu'),\n        tf.keras.layers.Dense(embeddingDim, activation=None), # No activation on final dense layer\n        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n    ])\n\n    model_tl.compile(\n        optimizer=tf.keras.optimizers.Adam(lr),\n        loss=tfa.losses.TripletSemiHardLoss())\n\n    model_tl.fit(x=x_train, y= y_train,\n                 batch_size=batch_size,\n                 epochs=EPOCHS,\n                 verbose=1) \n        \n    embedding_train_tl = []\n    for i in range(len(y_train)):\n        embedding_train_tl.append(model_tl.predict(x_train[i].reshape(1, imsize, imsize, 3))[0])\n        \n    embedding_train_tl = np.array(embedding_train_tl, dtype=float) \n\n    knn_tl = KNeighborsClassifier(n_neighbors = k)\n    knn_tl.fit(embedding_train_tl, y_train)\n    \n    x_test_embedding = model_tl.predict(x_val)\n    acc = round(knn_tl.score(x_test_embedding, y_val), 2)\n    print('Accuracy on the the val set with Tripolet Loss is {}'.format(acc))\n    \n    return acc","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:51:46.754439Z","iopub.execute_input":"2021-10-12T00:51:46.755155Z","iopub.status.idle":"2021-10-12T00:51:46.765865Z","shell.execute_reply.started":"2021-10-12T00:51:46.755118Z","shell.execute_reply":"2021-10-12T00:51:46.765183Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"lr = [1e-5, 1e-4, 1e-3, 1e-2]\nk = [1, 3, 5]\n\nterms = {}\nfor i in lr:\n    for j in k:\n        terms['{}_{}'.format(i, j)] = []\n        \nfor train_index, test_index in skf.split(X_train, Y_train):\n    x_train,x_val,y_train,y_val = X_train[train_index], X_train[test_index], Y_train[train_index], Y_train[test_index]\n    \n    for i in lr:\n        for j in k:\n            terms['{}_{}'.format(i, j)].append(evaluate_tl_closed_set(lr = i, k = j))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:51:46.766838Z","iopub.execute_input":"2021-10-12T00:51:46.767213Z","iopub.status.idle":"2021-10-12T01:11:11.177427Z","shell.execute_reply.started":"2021-10-12T00:51:46.767178Z","shell.execute_reply":"2021-10-12T01:11:11.176589Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nacc = pd.DataFrame(terms)\ntable_tl_closed_set = acc.agg(['mean', 'std']).T\ntable_tl_closed_set","metadata":{"execution":{"iopub.status.busy":"2021-10-12T01:11:11.179579Z","iopub.execute_input":"2021-10-12T01:11:11.179893Z","iopub.status.idle":"2021-10-12T01:11:11.205481Z","shell.execute_reply.started":"2021-10-12T01:11:11.179853Z","shell.execute_reply":"2021-10-12T01:11:11.204392Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Retrain Triplet Loss on trainset + val set, and test it on test set","metadata":{}},{"cell_type":"code","source":"# choose best lr and k\nlr = 0.0001\nk = 1\n\nbase_model_16 = tf.keras.applications.vgg16.VGG16(include_top=False,\n                                                  input_shape = (imsize, imsize, 3),\n                                                  weights = 'imagenet')\n\n# freeze all the layers of VGG, so they won't be trained.\nfor layer in base_model_16.layers:\n        layer.trainable = False\n\nmodel_tl = tf.keras.models.Sequential([\n    base_model_16,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=1024, activation='relu'),\n    tf.keras.layers.Dense(embeddingDim, activation=None), # No activation on final dense layer\n    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n])\n\nmodel_tl.compile(\n    optimizer=tf.keras.optimizers.Adam(lr),\n    loss=tfa.losses.TripletSemiHardLoss())\n\nmodel_tl.fit(x=X_train, y= Y_train,\n             batch_size=batch_size,\n             epochs=EPOCHS,\n             verbose=1) \n        \nembedding_train_tl = []\nfor i in range(len(Y_train)):\n    embedding_train_tl.append(model_tl.predict(X_train[i].reshape(1, imsize, imsize, 3))[0])\n        \nembedding_train_tl = np.array(embedding_train_tl, dtype=float) \n\nknn_tl = KNeighborsClassifier(n_neighbors = k)\nknn_tl.fit(embedding_train_tl, Y_train)\n    \nx_test_embedding = model_tl.predict(X_test)\nacc_tl_closed_set = round(knn_tl.score(x_test_embedding, Y_test), 2)\n\nprint('Accuracy of Triplet Loss on the test set is {}'.format(round(acc_tl_closed_set, 2)))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T01:12:38.642728Z","iopub.execute_input":"2021-10-12T01:12:38.643009Z","iopub.status.idle":"2021-10-12T01:13:27.158823Z","shell.execute_reply.started":"2021-10-12T01:12:38.642979Z","shell.execute_reply":"2021-10-12T01:13:27.158038Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Open Set","metadata":{}},{"cell_type":"code","source":"def evaluate_tl_open_set(lr = 0.0001, k = 1, d_t =0.5):\n    base_model_16 = tf.keras.applications.vgg16.VGG16(include_top=False,\n                                                      input_shape = (imsize, imsize, 3),\n                                                      weights = 'imagenet')\n\n    # freeze all the layers of VGG, so they won't be trained.\n    for layer in base_model_16.layers:\n        layer.trainable = False\n\n    model_tl = tf.keras.models.Sequential([\n        base_model_16,\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(units=1024, activation='relu'),\n        tf.keras.layers.Dense(embeddingDim, activation=None), # No activation on final dense layer\n        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n    ])\n\n    model_tl.compile(\n        optimizer=tf.keras.optimizers.Adam(lr),\n        loss=tfa.losses.TripletSemiHardLoss())\n\n    model_tl.fit(x=x_train, y= y_train,\n                 batch_size=batch_size,\n                 epochs=EPOCHS,\n                 verbose=1) \n        \n    embedding_train_tl = []\n    for i in range(len(y_train)):\n        embedding_train_tl.append(model_tl.predict(x_train[i].reshape(1, imsize, imsize, 3))[0])\n        \n    embedding_train_tl = np.array(embedding_train_tl, dtype=float) \n\n    knn_tl = KNeighborsClassifier(n_neighbors = k)\n    knn_tl.fit(embedding_train_tl, y_train)\n    \n    #find the center point for each class in training set\n    support_tl = []\n    for i in np.unique(y_train):\n        support_tl.append(np.mean(embedding_train_tl[y_train==i], axis=0))\n        \n    support_tl = np.array(support_tl, dtype=float)\n    \n    pred = []\n    temp_x = np.append(x_val, X_unseen, axis=0)\n    temp_y = np.append(y_val, Y_unseen, axis=0)\n    \n    arr = np.arange(temp_y.shape[0])\n    np.random.shuffle(arr)\n    \n    temp_x = temp_x[arr]\n    temp_y = temp_y[arr]\n    \n    for i in range(len(temp_y)):\n        dists = []\n        for j in range(len(np.unique(y_train))):\n            embedding_test = model_cl.predict(temp_x[i].reshape(1, 150, 150, 3))\n            embedding_anchor = support_tl[j]\n            dist = np.sum((embedding_test - embedding_anchor) ** 2) ** (1/2)\n            dists.append(dist)\n        if min(dists) >= d_t:\n            pred.append('unseen')\n        else:\n            pred.append(knn_tl.predict(embedding_test)[0])\n\n    pred = np.array(pred)\n    \n    acc_open = round(np.mean(pred == temp_y), 2)\n    print('The accuracy on the Open Dataset with triplet loss is {}'.format(acc_open))\n    \n    return acc_open","metadata":{"execution":{"iopub.status.busy":"2021-10-12T01:13:40.667635Z","iopub.execute_input":"2021-10-12T01:13:40.667910Z","iopub.status.idle":"2021-10-12T01:13:40.684164Z","shell.execute_reply.started":"2021-10-12T01:13:40.667882Z","shell.execute_reply":"2021-10-12T01:13:40.683330Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"d_t = [0.4, 0.5, 0.6]\n\nterms = {}\nfor i in d_t:\n    terms['{}'.format(i)] = []\n\nfor train_index, test_index in skf.split(X_train, Y_train):\n    x_train,x_val,y_train,y_val = X_train[train_index], X_train[test_index], Y_train[train_index], Y_train[test_index]\n    \n    for i in d_t:\n        terms['{}'.format(i)].append(evaluate_tl_open_set(d_t = i))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T01:13:43.615213Z","iopub.execute_input":"2021-10-12T01:13:43.615831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nacc = pd.DataFrame(terms)\ntable_tl_open_set = acc.agg(['mean', 'std']).T\ntable_tl_open_set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Retrain Triplet Loss on trainset + val set, and test it on test set","metadata":{}},{"cell_type":"code","source":"lr = 0.0001\nk = 1\nd_t = 0.4\n\nbase_model_16 = tf.keras.applications.vgg16.VGG16(include_top=False,\n                                                  input_shape = (imsize, imsize, 3),\n                                                  weights = 'imagenet')\n\n# freeze all the layers of VGG, so they won't be trained.\nfor layer in base_model_16.layers:\n    layer.trainable = False\n\nmodel_tl = tf.keras.models.Sequential([\n    base_model_16,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=1024, activation='relu'),\n    tf.keras.layers.Dense(embeddingDim, activation=None), # No activation on final dense layer\n    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n])\n\nmodel_tl.compile(\n    optimizer=tf.keras.optimizers.Adam(lr),\n    loss=tfa.losses.TripletSemiHardLoss())\n\nmodel_tl.fit(x = X_train, y = Y_train,\n             batch_size=batch_size,\n             epochs=EPOCHS,\n             verbose=1) \n        \nembedding_train_tl = []\nfor i in range(len(Y_train)):\n    embedding_train_tl.append(model_tl.predict(X_train[i].reshape(1, imsize, imsize, 3))[0])\n        \nembedding_train_tl = np.array(embedding_train_tl, dtype=float) \n\nknn_tl = KNeighborsClassifier(n_neighbors = k)\nknn_tl.fit(embedding_train_tl, Y_train)\n    \n#find the center point for each class in training set\nsupport_tl = []\nfor i in np.unique(Y_train):\n    support_tl.append(np.mean(embedding_train_tl[Y_train==i], axis=0))\n        \nsupport_tl = np.array(support_tl, dtype=float)\n    \npred = []\ntemp_x = np.append(X_test, X_unseen, axis=0)\ntemp_y = np.append(Y_test, Y_unseen, axis=0)\n    \narr = np.arange(temp_y.shape[0])\nnp.random.shuffle(arr)\n    \ntemp_x = temp_x[arr]\ntemp_y = temp_y[arr]\n    \nfor i in range(len(temp_y)):\n    dists = []\n    for j in range(len(np.unique(Y_train))):\n        embedding_test = model_tl.predict(temp_x[i].reshape(1, 150, 150, 3))\n        embedding_anchor = support_tl[j]\n        dist = np.sum((embedding_test - embedding_anchor) ** 2) ** (1/2)\n        dists.append(dist)\n    if min(dists) >= d_t:\n        pred.append('unseen')\n    else:\n        pred.append(knn_tl.predict(embedding_test)[0])\n\npred = np.array(pred)\n    \nacc_tl_open_set = round(np.mean(pred == temp_y), 2)\nprint('The accuracy on the test set with Open Dataset of Triplet Loss is {}'.format(acc_tl_open_set))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:43:26.775669Z","iopub.status.idle":"2021-10-12T00:43:26.776421Z","shell.execute_reply.started":"2021-10-12T00:43:26.776156Z","shell.execute_reply":"2021-10-12T00:43:26.776180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary on Closed Set","metadata":{}},{"cell_type":"code","source":"# After tuning hps (lr and k), the best accuracy on val set.\nbest_vgg16 = table_vgg16.loc['0.001']\nbest_cl = table_cl_closed_set.loc['0.0001_1']\nbest_tl = table_tl_closed_set.loc['0.0001_1']\n\npd.DataFrame({'VGG16_(LR = 0.0001)': best_vgg16,\n              'Contrastive_Loss(LR = 0.0001, k = 1)': best_cl, \n              'Triplet_Loss(LR = 0.0001, k = 1)': best_tl\n             })","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:43:26.777346Z","iopub.status.idle":"2021-10-12T00:43:26.778136Z","shell.execute_reply.started":"2021-10-12T00:43:26.777899Z","shell.execute_reply":"2021-10-12T00:43:26.777923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy on test set\n\npd.DataFrame([acc_vgg16, acc_cl_closed_set, acc_tl_closed_set], index = ['VGG16', 'Contrastive_Loss', 'Triplet_Loss'], columns = ['Accuracy']).T","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:43:26.779065Z","iopub.status.idle":"2021-10-12T00:43:26.779618Z","shell.execute_reply.started":"2021-10-12T00:43:26.779386Z","shell.execute_reply":"2021-10-12T00:43:26.779408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary on Open Set","metadata":{}},{"cell_type":"code","source":"# After tuning hps (d_t), the best accuracy on val set.\n\nbest_cl = table_cl_open_set.loc['0.4']\nbest_tl = table_tl_open_set.loc['0.4']\n\npd.DataFrame({'Contrastive_Loss(d_t = 0.4)': best_cl, \n              'Triplet_Loss(d_t = 0.4)': best_tl\n             })","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:43:26.780801Z","iopub.status.idle":"2021-10-12T00:43:26.781623Z","shell.execute_reply.started":"2021-10-12T00:43:26.781296Z","shell.execute_reply":"2021-10-12T00:43:26.781374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy on test set\n\npd.DataFrame([acc_cl_open_set, acc_tl_open_set], index = ['Contrastive_Loss', 'Triplet_Loss'], columns = ['Accuracy']).T","metadata":{"execution":{"iopub.status.busy":"2021-10-12T00:43:26.783132Z","iopub.status.idle":"2021-10-12T00:43:26.783583Z","shell.execute_reply.started":"2021-10-12T00:43:26.783350Z","shell.execute_reply":"2021-10-12T00:43:26.783372Z"},"trusted":true},"execution_count":null,"outputs":[]}]}